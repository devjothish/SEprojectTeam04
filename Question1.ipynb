{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def load_json(json_file_path):\n",
    "    \"\"\"Load JSON data from a file.\"\"\"\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "def preprocess_and_clean(json_data):\n",
    "\n",
    "    # Define a function to clean text\n",
    "    def clean_text(text):\n",
    "        if text is not None:\n",
    "            # Remove Unicode escape sequences\n",
    "            cleaned_text = text.encode('utf-8').decode('unicode-escape')\n",
    "            # Remove emoji symbols\n",
    "            cleaned_text = cleaned_text.encode('ascii', 'ignore').decode('ascii')\n",
    "            # Remove extra whitespaces\n",
    "            cleaned_text = re.sub(r'\\s+', ' ', cleaned_text).strip()\n",
    "            return cleaned_text\n",
    "        return None\n",
    "\n",
    "    # Define a function to convert date strings to datetime objects\n",
    "    def convert_to_datetime(date_str):\n",
    "        if date_str is not None:\n",
    "            return datetime.strptime(date_str, '%Y-%m-%dT%H:%M:%SZ')\n",
    "        return None\n",
    "\n",
    "    # Clean and handle null values for top-level attributes\n",
    "    json_data['CreatedAt'] = convert_to_datetime(json_data.get('CreatedAt'))\n",
    "    json_data['ClosedAt'] = convert_to_datetime(json_data.get('ClosedAt'))\n",
    "    json_data['MergedAt'] = convert_to_datetime(json_data.get('MergedAt'))\n",
    "    json_data['UpdatedAt'] = convert_to_datetime(json_data.get('UpdatedAt'))\n",
    "    json_data['Title'] = clean_text(json_data.get('Title'))\n",
    "    json_data['Body'] = clean_text(json_data.get('Body'))\n",
    "\n",
    "    # Clean and handle null values for nested conversation data\n",
    "    if 'ChatgptSharing' in json_data:\n",
    "        for convo in json_data['ChatgptSharing']:\n",
    "            convo['URL'] = clean_text(convo.get('URL'))\n",
    "            convo['Title'] = clean_text(convo.get('Title'))\n",
    "            convo['DateOfConversation'] = convert_to_datetime(convo.get('DateOfConversation'))\n",
    "\n",
    "            if 'Conversations' in convo:\n",
    "                convo['Conversations'] = [\n",
    "                    {\n",
    "                        'Prompt': clean_text(c.get('Prompt')),\n",
    "                        'Answer': clean_text(c.get('Answer')),\n",
    "                        'ListOfCode': c.get('ListOfCode') if 'ListOfCode' in c else None\n",
    "                    }\n",
    "                    for c in convo['Conversations']\n",
    "                ]\n",
    "\n",
    "    return json_data\n",
    "\n",
    "def extract_prompt_counts(source, state):\n",
    "    \"\"\"Extract the prompt counts from the given source and state.\"\"\"\n",
    "    prompts = []\n",
    "    for entry in source['ChatgptSharing']:\n",
    "        if 'NumberOfPrompts' in entry and entry['NumberOfPrompts'] is not None:\n",
    "            prompts.append(entry['NumberOfPrompts'])\n",
    "    return prompts\n",
    "\n",
    "def calculate_average(prompt_list):\n",
    "    \"\"\"Calculate the average of a list of prompt counts.\"\"\"\n",
    "    if not prompt_list:\n",
    "        return 0\n",
    "    return round(sum(prompt_list) / len(prompt_list))\n",
    "   \n",
    "def AvgPromptCount(json_file_path_pr, json_file_path_issue):\n",
    "    \"\"\"Calculate and plot the average prompt counts for open and closed states.\"\"\"\n",
    "\n",
    "    data_pr = load_json(json_file_path_pr)\n",
    "    cleaned_data_pr = preprocess_and_clean(data_pr)\n",
    "\n",
    "    data_issue = load_json(json_file_path_issue)\n",
    "    cleaned_data_issue = preprocess_and_clean(data_issue)\n",
    "\n",
    "    opened_pr, closed_pr = [], []\n",
    "    opened_issue, closed_issue = [], []\n",
    "\n",
    "    for source in cleaned_data_pr['Sources']:\n",
    "        if source['State'] == \"CLOSED\":\n",
    "            closed_pr.extend(extract_prompt_counts(source, 'CLOSED'))\n",
    "        else:\n",
    "            opened_pr.extend(extract_prompt_counts(source, 'OPEN'))\n",
    "\n",
    "    avg_opened_pr = calculate_average(opened_pr)\n",
    "    avg_closed_pr = calculate_average(closed_pr)\n",
    "\n",
    "    for source in cleaned_data_issue['Sources']:\n",
    "        if source['State'] == \"CLOSED\":\n",
    "            closed_issue.extend(extract_prompt_counts(source, 'CLOSED'))\n",
    "        else:\n",
    "            opened_issue.extend(extract_prompt_counts(source, 'OPEN'))\n",
    "\n",
    "    avg_opened_issue = calculate_average(opened_issue)\n",
    "    avg_closed_issue = calculate_average(closed_issue)\n",
    "\n",
    "\n",
    "json_file_path_pr = 'Snapshots/20230831_060603_pr_sharings.json'\n",
    "json_file_path_issue = 'Snapshots/20230831_061759_issue_sharings.json'\n",
    "\n",
    "AvgPromptCount(json_file_path_pr, json_file_path_issue)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
